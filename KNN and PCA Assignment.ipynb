{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cac76182-ec1e-42b4-baf6-65de41c4bace",
   "metadata": {},
   "outputs": [],
   "source": [
    "#21 Train a KNN Classifier on the Iris dataset and print model accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e3f7f66e-bb24-494b-9b1c-79a1bb303e1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4e801e3e-9e2a-413d-b5a1-4e2fadb7d435",
   "metadata": {},
   "outputs": [],
   "source": [
    "x,y = load_iris(return_X_y = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1625cacf-09fa-41f6-b365-1c1ad2239e96",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy_Score of the model 1.0\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "x_train,x_test,y_train,y_test = train_test_split(x,y,test_size = 0.25,random_state = 1)\n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "model = KNeighborsClassifier(n_neighbors = 5,weights = 'uniform')\n",
    "model.fit(x_train,y_train)\n",
    "y_pred = model.predict(x_test)\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "print(\"Accuracy_Score of the model\",accuracy_score(y_test,y_pred)\n",
    "     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2155749f-c3e2-44d1-838c-c87057458a42",
   "metadata": {},
   "outputs": [],
   "source": [
    "#22 train a KNN Regressor on a synthetic dataset and evaluate using Mean Squared Error (MSE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e47abefd-7dc6-4ff5-ade2-0555299a434a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import make_regression\n",
    "x,y = make_regression(n_samples = 1000,n_features = 5,noise = 0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3438cb1d-18ad-4e03-9ce4-d457ed26fd15",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean_squared_error 1131.3563533492247\n"
     ]
    }
   ],
   "source": [
    "x_train,x_test,y_train,y_test = train_test_split(x,y,test_size = 0.25,random_state = 1)\n",
    "\n",
    "from sklearn.neighbors import KNeighborsRegressor \n",
    "\n",
    "model = KNeighborsRegressor(n_neighbors = 5,weights = 'distance',leaf_size = 20)\n",
    "model.fit(x_train,y_train)\n",
    "y_pred = model.predict(x_test)\n",
    "\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "print(\"Mean_squared_error\",mean_squared_error(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "14ed6d4b-2b13-405b-9650-873b0e3e1686",
   "metadata": {},
   "outputs": [],
   "source": [
    "#23 Train a KNN Classifier using different distance metrics (Euclidean and Manhattan) and compare accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3de2cc11-5e3e-4f13-90aa-f57842faa5d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy_Score of the model distance of Euclidean 1.0\n",
      "Accuracy_Score of the model distance of Manhattan 1.0\n"
     ]
    }
   ],
   "source": [
    "x,y = load_iris(return_X_y = True)\n",
    "x_train,x_test,y_train,y_test = train_test_split(x,y,test_size = 0.25,random_state = 1)\n",
    "\n",
    "model = KNeighborsClassifier(n_neighbors = 5,weights = 'uniform',metric = \"euclidean\")\n",
    "model.fit(x_train,y_train)\n",
    "y_pred = model.predict(x_test)\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "print(\"Accuracy_Score of the model distance of Euclidean\",accuracy_score(y_test,y_pred))\n",
    "\n",
    "model = KNeighborsClassifier(n_neighbors = 5,weights = 'uniform',metric = \"manhattan\")\n",
    "model.fit(x_train,y_train)\n",
    "y_pred = model.predict(x_test)\n",
    "\n",
    "print(\"Accuracy_Score of the model distance of Manhattan\",accuracy_score(y_test,y_pred))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3f91bef2-2cc3-4ea6-ab88-539d79aac7e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#24 Train a KNN Classifier with different values of K and visualize decision boundaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8fb3a20-34d7-40d1-8210-b54380109c82",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from matplotlib.colors import ListedColormap\n",
    "\n",
    "# Create a 2D classification dataset\n",
    "X, y = make_classification(n_classes=2, n_features=2, n_informative=2, n_redundant=0, random_state=42, n_clusters_per_class=1)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=1)\n",
    "# Create a mesh grid\n",
    "x_min, x_max = X[:, 0].min() - 1, X[:, 0].max() + 1\n",
    "y_min, y_max = X[:, 1].min() - 1, X[:, 1].max() + 1\n",
    "xx, yy = np.meshgrid(np.arange(x_min, x_max, 0.01), np.arange(y_min, y_max, 0.01))\n",
    "\n",
    "# Different values of K\n",
    "k_values = [1, 5, 15]\n",
    "\n",
    "# Plot decision boundaries\n",
    "plt.figure(figsize=(15, 5))\n",
    "for i, k in enumerate(k_values, 1):\n",
    "    knn = KNeighborsClassifier(n_neighbors=k)\n",
    "    knn.fit(X_train, y_train)\n",
    "    \n",
    "    # Predict on mesh grid\n",
    "    Z = knn.predict(np.c_[xx.ravel(), yy.ravel()])\n",
    "    Z = Z.reshape(xx.shape)\n",
    "    \n",
    "    # Plot\n",
    "    plt.subplot(1, len(k_values), i)\n",
    "    plt.contourf(xx, yy, Z, alpha=0.6, cmap=ListedColormap(['#FFAAAA', '#AAAAFF']))\n",
    "    plt.scatter(X_train[:, 0], X_train[:, 1], c=y_train, edgecolor='k', cmap=ListedColormap(['#FF0000', '#0000FF']))\n",
    "    plt.title(f\"K = {k}\")\n",
    "    plt.xlabel(\"Feature 1\")\n",
    "    plt.ylabel(\"Feature 2\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc174d3f-383d-4f5a-b173-f4c26b2e8f3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#25 Apply Feature Scaling before training a KNN model and compare results with unscaled data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcab96e0-0c73-4aef-886b-16f63d489698",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import make_regression\n",
    "x,y = make_regression(n_samples = 1000,n_features = 5,noise = 0.25)\n",
    "x_train,x_test,y_train,y_test = train_test_split(x,y,test_size = 0.25,random_state = 1)\n",
    "model = KNeighborsRegressor()\n",
    "model.fit(x_train,y_train)\n",
    "\n",
    "y_pred = model.predict(x_test)\n",
    "\n",
    "\n",
    "print(\"MSE unScaled Data\",mean_squared_error(y_test,y_pred))\n",
    "print()\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "\n",
    "scaled = scaler.fit_transform(x)\n",
    "x_train,x_test,y_train,y_test = train_test_split(scaled,y,test_size = 0.25,random_state = 1)\n",
    "model = KNeighborsRegressor()\n",
    "model.fit(x_train,y_train)\n",
    "\n",
    "y_pred = model.predict(x_test)\n",
    "\n",
    "\n",
    "print(\"MSE Scaled Data\",mean_squared_error(y_test,y_pred))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0c6fe34-9a58-4b6f-be6f-9ddbd1d1e80f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#26 Train a PCA model on synthetic data and print the explained variance ratio for each component"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73899c1b-f40a-45d2-8e81-1affcb4e685c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "# Step 1: Generate synthetic data\n",
    "np.random.seed(42)\n",
    "# Creating a dataset with 100 samples and 5 features\n",
    "data = np.random.rand(100, 5)\n",
    "\n",
    "# Step 2: Standardize the data (optional, but recommended)\n",
    "# PCA is sensitive to the scale of the data, so it's a good idea to normalize it.\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "data_normalized = scaler.fit_transform(data)\n",
    "\n",
    "# Step 3: Train the PCA model\n",
    "pca = PCA()  # No need to specify the number of components; it'll compute all.\n",
    "pca.fit(data_normalized)\n",
    "\n",
    "# Step 4: Print explained variance ratio for each component\n",
    "print(\"Explained Variance Ratio for each component:\")\n",
    "for i, ratio in enumerate(pca.explained_variance_ratio_):\n",
    "    print(f\"Component {i+1}: {ratio:.4f}\")\n",
    "\n",
    "# Bonus: Cumulative explained variance\n",
    "cumulative_variance = np.cumsum(pca.explained_variance_ratio_)\n",
    "print(\"\\nCumulative Explained Variance:\")\n",
    "for i, cum_var in enumerate(cumulative_variance):\n",
    "    print(f\"Up to Component {i+1}: {cum_var:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "675149f3-674d-40b9-8690-f046c87036d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 27 Apply PCA before training a KNN Classifier and compare accuracy with and without PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10cd6f21-afc8-4297-8f10-1ad3bbf7f58f",
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = make_classification(n_classes=2, n_features=2, n_informative=2, n_redundant=0, random_state=42, n_clusters_per_class=1)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=1)\n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "model = KNeighborsClassifier(n_neighbors = 5,weights = \"distance\",metric = \"euclidean\")\n",
    "\n",
    "model.fit(X_train,y_train)\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "print(\"Accuracy Of model without PCA\",accuracy_score(y_test,y_pred))\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "from sklearn.decomposition import PCA\n",
    "pca = PCA()\n",
    "X_train = pca.fit_transform(X_train)\n",
    "X_test = pca.transform(X_test)\n",
    "\n",
    "\n",
    "model.fit(X_train,y_train)\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "print(\"Accuracy Of model without PCA\",accuracy_score(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb8d30cb-600e-47e4-9936-e8fae303e889",
   "metadata": {},
   "outputs": [],
   "source": [
    "#28 Perform Hyperparameter Tuning on a KNN Classifier using GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c808493-cb0f-4a38-9b9d-5974dcfd637c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "param = {\"n_neighbors\":[1,2,3,4,5],'weights':[\"distance\",\"uniform\"],\"metric\":[\"euclidean\",\"manhattan\"]}\n",
    "model = GridSearchCV(KNeighborsClassifier(),param_grid = param,cv = 5,verbose = 3)\n",
    "model.fit(X_train,y_train)\n",
    "print()\n",
    "print()\n",
    "print(model.best_params_)\n",
    "print(\"accuracy_Score\",accuracy_score(y_test,model.predict(X_test)))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3acb9ea-8195-40c1-8eeb-d27bfcaca17a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 29 Train a KNN Classifier and check the number of misclassified samples5\n",
    "\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5b3bcd1-f169-4dad-9f4c-3970931fcc4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion_matrix(y_test,y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f84a2dcd-5e8d-4d23-b02f-41602b0cd6e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 30 Train a PCA model and visualize the cumulative explained variance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b68f9932-4aee-4637-be50-688bf7a14f34",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.datasets import load_iris\n",
    "\n",
    "# Load the dataset (Iris dataset as an example)\n",
    "data = load_iris()\n",
    "X = data.data  # Features\n",
    "\n",
    "# Train the PCA model\n",
    "pca = PCA()\n",
    "pca.fit(X)\n",
    "\n",
    "# Get the explained variance ratio\n",
    "explained_variance_ratio = pca.explained_variance_ratio_\n",
    "cumulative_variance = np.cumsum(explained_variance_ratio)\n",
    "\n",
    "# Plot the cumulative explained variance\n",
    "plt.figure(figsize=(8, 5))\n",
    "plt.plot(range(1, len(cumulative_variance) + 1), cumulative_variance, marker='o', linestyle='--', color='b')\n",
    "plt.xlabel('Number of Principal Components')\n",
    "plt.ylabel('Cumulative Explained Variance')\n",
    "plt.title('PCA: Cumulative Explained Variance')\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3c035c0-00f3-4039-855c-bf1c25789c72",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 31 Train a KNN Classifier using different values of the weights parameter (uniform vs. distance) and compare accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13b85daf-583a-4009-a3f5-18c21f4e5298",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = KNeighborsClassifier(weights = \"uniform\")\n",
    "model.fit(X_train,y_train)\n",
    "y_pred = model.predict(X_test)\n",
    "print(\"Accuracy Score when Weight parameter is uniform\",accuracy_score(y_test,y_pred))\n",
    "print()\n",
    "print()\n",
    "model = KNeighborsClassifier(weights = \"distance\")\n",
    "model.fit(X_train,y_train)\n",
    "y_pred = model.predict(X_test)\n",
    "print(\"Accuracy Score when Weight parameter is uniform\",accuracy_score(y_test,y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f685b6eb-8f4e-4999-a915-8e2429653975",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 32   Train a KNN Regressor and analyze the effect of different K values on performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2534370c-6f4a-42ee-9d43-27c196bd0b24",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.datasets import make_regression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# Generate synthetic regression dataset\n",
    "X, y = make_regression(n_samples=500, n_features=1, noise=10, random_state=42)\n",
    "\n",
    "# Split data into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Initialize variables\n",
    "k_values = range(1, 21)  # K values from 1 to 20\n",
    "mse_values = []\n",
    "\n",
    "# Train and evaluate KNN Regressor for each K\n",
    "for k in k_values:\n",
    "    knn = KNeighborsRegressor(n_neighbors=k)\n",
    "    knn.fit(X_train, y_train)\n",
    "    y_pred = knn.predict(X_test)\n",
    "    mse = mean_squared_error(y_test, y_pred)\n",
    "    mse_values.append(mse)\n",
    "\n",
    "# Plot MSE vs. K values\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(k_values, mse_values, marker='o')\n",
    "plt.title('Effect of K on KNN Regressor Performance')\n",
    "plt.xlabel('Number of Neighbors (K)')\n",
    "plt.ylabel('Mean Squared Error (MSE)')\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c47a69f-4517-4568-9126-0c2861ee6151",
   "metadata": {},
   "outputs": [],
   "source": [
    "#33 4Implement KNN Imputation for handling missing values in a dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94123ca6-5c20-4101-8f13-348f2158c7d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.impute import KNNImputer\n",
    "\n",
    "# Create a sample dataset with missing values\n",
    "data = {\n",
    "    'Feature1': [1, 2, np.nan, 4],\n",
    "    'Feature2': [np.nan, 2, 3, 4],\n",
    "    'Feature3': [1, np.nan, 3, 4]\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "print(\"Original Dataset:\")\n",
    "print(df)\n",
    "\n",
    "# Initialize KNN Imputer\n",
    "imputer = KNNImputer(n_neighbors=2)\n",
    "\n",
    "# Apply KNN Imputation\n",
    "imputed_data = imputer.fit_transform(df)\n",
    "imputed_df = pd.DataFrame(imputed_data, columns=df.columns)\n",
    "\n",
    "print(\"\\nDataset after KNN Imputation:\")\n",
    "print(imputed_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83a58e15-92d5-4564-8728-5f0ecbf086de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 34 Train a PCA model and visualize the data projection onto the first two principal components4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5ddb02f-2ae7-4e6b-a187-99c781259c61",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Load dataset\n",
    "data = load_iris()\n",
    "X = data.data\n",
    "y = data.target\n",
    "target_names = data.target_names\n",
    "\n",
    "# Standardize the features\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# Train PCA\n",
    "pca = PCA(n_components=2)  # Keep the first 2 principal components\n",
    "X_pca = pca.fit_transform(X_scaled)\n",
    "\n",
    "# Print explained variance ratio\n",
    "print(\"Explained Variance Ratio:\", pca.explained_variance_ratio_)\n",
    "\n",
    "# Visualize the projection\n",
    "plt.figure(figsize=(10, 7))\n",
    "for target, color, label in zip([0, 1, 2], ['r', 'g', 'b'], target_names):\n",
    "    plt.scatter(X_pca[y == target, 0], X_pca[y == target, 1], alpha=0.7, color=color, label=label)\n",
    "\n",
    "plt.title(\"PCA Projection onto First Two Components\")\n",
    "plt.xlabel(\"Principal Component 1\")\n",
    "plt.ylabel(\"Principal Component 2\")\n",
    "plt.legend(loc='best')\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86fa121f-daa8-4388-84a1-0d2de5cf99b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#35 Train a PCA model on a high-dimensional dataset and visualize the Scree plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "596067ad-946e-45a8-91ce-0584cd837f9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generating random high-dimensional data\n",
    "np.random.seed(42)\n",
    "X = np.random.rand(100, 50)  # 100 samples, 50 features\n",
    "# Train PCA on the dataset\n",
    "pca = PCA()\n",
    "pca.fit(X)\n",
    "# Calculate explained variance ratio\n",
    "explained_variance_ratio = pca.explained_variance_ratio_\n",
    "# Scree plot visualization\n",
    "plt.figure(figsize=(8, 5))\n",
    "plt.plot(range(1, len(explained_variance_ratio) + 1), explained_variance_ratio, marker='o', linestyle='--')\n",
    "plt.title('Scree Plot')\n",
    "plt.xlabel('Principal Component')\n",
    "plt.ylabel('Explained Variance Ratio')\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b58d1df-5c16-4a34-a13f-4a7e4c8a5425",
   "metadata": {},
   "outputs": [],
   "source": [
    "#36 Train a KNN Classifier and evaluate performance using Precision, Recall, and F1-Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0aa243d5-061b-4e6f-bdc8-6f8572aa08dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "data = load_iris()\n",
    "X = data.data\n",
    "y = data.target\n",
    "target_names = data.target_names\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "model = KNeighborsClassifier(weights = \"uniform\",algorithm = \"kd_tree\")\n",
    "from sklearn.model_selection import train_test_split\n",
    "x_train,x_test,y_train,y_test = train_test_split(X,y,test_size = 0.25,random_state = 1)\n",
    "model.fit(x_train,y_train)\n",
    "y_pred = model.predict(x_test)\n",
    "\n",
    "from sklearn.metrics import precision_score,recall_score,f1_score\n",
    "\n",
    "print(\"precision\",precision_score(y_test,y_pred,average = \"weighted\"))\n",
    "print(\"recall\",recall_score(y_test,y_pred,average = 'weighted'))\n",
    "print(\"f1_score:\")\n",
    "print(f1_score(y_test,y_pred,average = 'weighted'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd2d0761-24cf-4d97-a8e6-67c6feab45d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#38 Train a PCA Model and Analyze Accuracy with Different Numbers of Components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0007b657-55f5-4239-8f9a-750cd124b599",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "import numpy as np\n",
    "\n",
    "# Load a sample dataset\n",
    "from sklearn.datasets import load_digits\n",
    "data = load_digits()\n",
    "X, y = data.data, data.target\n",
    "\n",
    "# Split dataset\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Experiment with different numbers of components\n",
    "for n in [10, 20, 30, 40]:\n",
    "    pca = PCA(n_components=n)\n",
    "    X_train_pca = pca.fit_transform(X_train)\n",
    "    X_test_pca = pca.transform(X_test)\n",
    "    \n",
    "    clf = LogisticRegression(max_iter=1000)\n",
    "    clf.fit(X_train_pca, y_train)\n",
    "    y_pred = clf.predict(X_test_pca)\n",
    "    \n",
    "    print(f\"Components: {n}, Accuracy: {accuracy_score(y_test, y_pred):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "249a8863-6738-4e6d-a778-2b7523bff6d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#39 Train a KNN Classifier with Different  Values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f87aadac-c76b-416b-bcde-229a14e981c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "leaf_sizes = [10, 30, 50]\n",
    "for leaf_size in leaf_sizes:\n",
    "    knn = KNeighborsClassifier(leaf_size=leaf_size)\n",
    "    knn.fit(X_train, y_train)\n",
    "    y_pred = knn.predict(X_test)\n",
    "    print(f\"Leaf Size: {leaf_size}, Accuracy: {accuracy_score(y_test, y_pred):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7366f7ef-2ab6-46e4-8399-7ed69b95617f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#40 Visualize Data Transformation Before and After PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d305e22-ecfb-4bd7-a5c2-0486cced4735",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Apply PCA to reduce to 2 dimensions for visualization\n",
    "pca = PCA(n_components=2)\n",
    "X_pca = pca.fit_transform(X)\n",
    "\n",
    "# Plot original data (high-dimensional) vs reduced data (2D)\n",
    "plt.scatter(X_pca[:, 0], X_pca[:, 1], c=y, cmap='viridis', edgecolor='k')\n",
    "plt.title(\"Data After PCA (2D Projection)\")\n",
    "plt.xlabel(\"Principal Component 1\")\n",
    "plt.ylabel(\"Principal Component 2\")\n",
    "plt.colorbar(label='Target')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c832b94b-08b8-4f25-b21e-5819bae380e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#41 Train KNN on a Real-World Dataset (Wine) and Print Classification Report\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "281cf93f-18ce-4efb-87f9-2b52acc54438",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_wine\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Load Wine dataset\n",
    "data = load_wine()\n",
    "X, y = data.data, data.target\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "knn = KNeighborsClassifier()\n",
    "knn.fit(X_train, y_train)\n",
    "y_pred = knn.predict(X_test)\n",
    "\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7dbf21c-4d60-42ed-b6b5-7d47d1e40fd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#42 Train a KNN Regressor and Compare Distance Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f602864-d54f-4d91-b5af-b7cb9151d90f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# Synthetic regression dataset\n",
    "from sklearn.datasets import make_regression\n",
    "X, y = make_regression(n_samples=200, n_features=5, noise=0.1)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Experiment with different distance metrics\n",
    "metrics = ['euclidean', 'manhattan', 'minkowski']\n",
    "for metric in metrics:\n",
    "    knn_reg = KNeighborsRegressor(metric=metric)\n",
    "    knn_reg.fit(X_train, y_train)\n",
    "    y_pred = knn_reg.predict(X_test)\n",
    "    print(f\"Metric: {metric}, MSE: {mean_squared_error(y_test, y_pred):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7e904f0-f24e-4cb8-9482-1ba1d4b41e1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#43 Evaluate KNN Classifier Using ROC-AUC Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "591b0c7d-956c-465a-baba-761e75260b63",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.preprocessing import label_binarize\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.datasets import load_iris\n",
    "import numpy as np\n",
    "\n",
    "# Load sample dataset\n",
    "data = load_iris()\n",
    "X, y = data.data, data.target\n",
    "\n",
    "# Split into train and test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Binarize labels for multiclass ROC-AUC\n",
    "y_train_bin = label_binarize(y_train, classes=np.unique(y))\n",
    "y_test_bin = label_binarize(y_test, classes=np.unique(y))\n",
    "\n",
    "# Train KNN Classifier\n",
    "knn = KNeighborsClassifier()\n",
    "knn.fit(X_train, y_train)\n",
    "\n",
    "# Predict probabilities\n",
    "y_score = knn.predict_proba(X_test)\n",
    "\n",
    "# Compute ROC-AUC Score\n",
    "roc_auc = roc_auc_score(y_test_bin, y_score, multi_class='ovr')\n",
    "print(f\"ROC-AUC Score: {roc_auc:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25275d0d-d42e-4306-b5ff-172260663bbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#44 Visualize Variance Captured by PCA Components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fddb74bc-c227-4ad8-8cf6-42c841c8ebee",
   "metadata": {},
   "outputs": [],
   "source": [
    "explained_variance_ratio = pca.explained_variance_ratio_\n",
    "plt.plot(range(1, len(explained_variance_ratio) + 1), explained_variance_ratio, marker='o')\n",
    "plt.title(\"Explained Variance by PCA Components\")\n",
    "plt.xlabel(\"Principal Components\")\n",
    "plt.ylabel(\"Explained Variance Ratio\")\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4ec4066-c706-45cb-b65c-77ca5c3a32e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 45 Feature Selection Before Training KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fedb0f69-86fe-4ebe-8ea8-7662ffc0eaad",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import SelectKBest, mutual_info_classif\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Set k to a value less than or equal to the number of features\n",
    "k = 3  # Choose top 3 features (you can adjust this)\n",
    "selector = SelectKBest(score_func=mutual_info_classif, k=k)\n",
    "X_selected = selector.fit_transform(X, y)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_selected, y, test_size=0.3, random_state=42)\n",
    "\n",
    "knn = KNeighborsClassifier()\n",
    "knn.fit(X_train, y_train)\n",
    "y_pred = knn.predict(X_test)\n",
    "\n",
    "print(f\"Accuracy with Feature Selection: {accuracy_score(y_test, y_pred):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f246a7e2-939b-4eaa-9ed8-f91d9f172a0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#46 Visualize Data Reconstruction Error After PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b8c8f98-f472-470f-ac3d-cfc022bec1bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "reconstruction_error = []\n",
    "for n in range(1, X.shape[1] + 1):\n",
    "    pca = PCA(n_components=n)\n",
    "    X_pca = pca.fit_transform(X)\n",
    "    X_reconstructed = pca.inverse_transform(X_pca)\n",
    "    error = np.mean((X - X_reconstructed) ** 2)\n",
    "    reconstruction_error.append(error)\n",
    "\n",
    "plt.plot(range(1, X.shape[1] + 1), reconstruction_error, marker='o')\n",
    "plt.title(\"Reconstruction Error vs PCA Components\")\n",
    "plt.xlabel(\"Number of Components\")\n",
    "plt.ylabel(\"Reconstruction Error\")\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1983f17a-45d7-4e6b-b879-11f2bf1f0853",
   "metadata": {},
   "outputs": [],
   "source": [
    "#47 Visualize Decision Boundary of KNN Classifier\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea685061-a269-42bb-a1a7-4c8213636a5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import make_moons\n",
    "\n",
    "# Create 2D dataset\n",
    "X, y = make_moons(n_samples=200, noise=0.2, random_state=42)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "knn = KNeighborsClassifier(n_neighbors=5)\n",
    "knn.fit(X_train, y_train)\n",
    "\n",
    "# Decision boundary visualization\n",
    "xx, yy = np.meshgrid(np.arange(X[:, 0].min() - 1, X[:, 0].max() + 1, 0.1),\n",
    "                     np.arange(X[:, 1].min() - 1, X[:, 1].max() + 1, 0.1))\n",
    "Z = knn.predict(np.c_[xx.ravel(), yy.ravel()])\n",
    "Z = Z.reshape(xx.shape)\n",
    "\n",
    "plt.contourf(xx, yy, Z, alpha=0.8, cmap='coolwarm')\n",
    "plt.scatter(X[:, 0], X[:, 1], c=y, edgecolor='k', cmap='coolwarm')\n",
    "plt.title(\"KNN Decision Boundary\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7ea4bed-398e-4815-ad99-ec85badeb342",
   "metadata": {},
   "outputs": [],
   "source": [
    "#8 Train a PCA model and analyze the effect of different numbers of components on data variance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd3fc4e6-60b4-4edb-916f-a001575a541e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.datasets import load_digits\n",
    "\n",
    "# Load a dataset (example: Digits dataset)\n",
    "data = load_digits()\n",
    "X = data.data\n",
    "\n",
    "# Initialize an empty list to store explained variance ratios\n",
    "explained_variance_ratios = []\n",
    "\n",
    "# Iterate through different numbers of principal components\n",
    "num_components = range(1, X.shape[1] + 1)\n",
    "for n in num_components:\n",
    "    pca = PCA(n_components=n)\n",
    "    pca.fit(X)\n",
    "    explained_variance_ratios.append(sum(pca.explained_variance_ratio_))\n",
    "\n",
    "# Plot explained variance against number of components\n",
    "plt.figure(figsize=(8, 5))\n",
    "plt.plot(num_components, explained_variance_ratios, marker='o', linestyle='--', color='b')\n",
    "plt.title(\"Effect of Number of PCA Components on Data Variance\")\n",
    "plt.xlabel(\"Number of Principal Components\")\n",
    "plt.ylabel(\"Total Explained Variance\")\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "647a0d64-3ec4-4b68-b4af-9044bbab4d00",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
